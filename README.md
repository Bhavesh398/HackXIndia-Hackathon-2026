# Truefy: Deepfake Forensics Platform

End-to-end system to detect AI-generated media across images, videos, and audio. Combines a FastAPI + PyTorch backend with a modern Vite + React frontend.
Google drive video link = https://drive.google.com/drive/folders/1iV4w0_NE8Bz9H_0CYxqlBKkN0JYps9Km?usp=drive_link
## Architecture
- Backend: FastAPI service with image, video, and audio analysis. See BACKEND.
- Frontend: React UI to upload media and display analysis. See FRONTEND.
- Models & datasets: Stored under BACKEND/models and BACKEND/datasets.

## Quick Start (Windows)
1. Backend
   ```powershell
   cd BACKEND
   python -m venv venv
   venv\Scripts\activate
   pip install -r requirements.txt
   uvicorn backend.app:app --reload --host 127.0.0.1 --port 8000
   ```
2. Frontend
   ```powershell
   cd FRONTEND
   npm install
   npm run dev
   ```
3. Open the frontend URL (usually http://127.0.0.1:5173) and upload media.

## API Contract
POST /predict (multipart `file`)
```json
{
  "type": "image" | "video" | "audio",
  "fake_probability": number,   // 0-100
  "real_probability": number,   // 0-100
  "verdict": "FAKE" | "REAL" | "UNCERTAIN",
  "confidence": number          // 0-100
}
```

## Common Issues
- CORS: Backend must allow localhost:5173 (already configured).
- Missing models: Place .pth files in BACKEND/models.
- GPU/CPU: Backend auto-selects CUDA if available, else CPU.

## Project Goals
- Reliable local verification for media authenticity.
- Clear UI explaining probabilities and risk.
- Modular pipelines for image/video/audio.

For more details, read BACKEND/README.md and FRONTEND/README.md.

What This System Does
DeepScan detects manipulated or AI-generated media using multiple forensic signals, not just a single neural network prediction.
It supports:
ðŸ–¼ï¸ Images (GAN / diffusion generated faces)
ðŸŽžï¸ Videos (frame-level analysis + robust aggregation)
ðŸ”Š Audio (voice synthesis detection)
Each prediction returns:
Probability (real vs fake)
Confidence score
A safe UNCERTAIN state when the model is unsure
ðŸ§  Why â€œUNCERTAINâ€ Exists
Real forensic systems never force a binary answer.
DeepScan avoids dangerous false accusations by introducing an UNCERTAIN verdict when the evidence is inconclusive.
This is critical for:
Legal use cases
Journalism
Security & trust systems
Responsible AI deployment
ðŸ§© System Architecture (How It Works)
User Upload
   â”‚
   â–¼
FastAPI Backend
   â”‚
   â”œâ”€â”€ Image Analysis (CNN)
   â”œâ”€â”€ Video Frame Analysis
   â”œâ”€â”€ Audio Spectral Analysis
   â”œâ”€â”€ Probability Calibration
   â””â”€â”€ Decision Engine
          â”œâ”€â”€ REAL
          â”œâ”€â”€ FAKE
          â””â”€â”€ UNCERTAIN
ðŸ” Image Detection Pipeline
Image is resized & normalized
CNN extracts spatial artifacts
Model detects:
Texture inconsistencies
GAN artifacts
Synthetic patterns
Softmax probabilities are calibrated
Final verdict is produced using thresholds
Example logic:
if fake_prob >= 0.7:
    verdict = "FAKE"
elif fake_prob <= 0.3:
    verdict = "REAL"
else:
    verdict = "UNCERTAIN"
ðŸŽžï¸ Video Detection Pipeline
Videos are not classified as a whole.
Instead:
Frames are extracted every N frames
Each frame is analyzed independently
Only the most suspicious frames influence the result
Outliers are trimmed to avoid noise
Final probability is aggregated safely
This prevents:
Single bad frame â†’ false fake
Motion blur false positives
ðŸ”Š Audio Detection Pipeline
Audio detection is based on spectral analysis, not speech content.
Audio converted to mono WAV
MFCC & frequency features extracted
Voice synthesis artifacts detected
Model predicts fake probability
Threshold-based verdict returned
ðŸ“ Project Structure
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                # FastAPI server
â”‚   â”œâ”€â”€ models/               # Image & audio models
â”‚   â”œâ”€â”€ preprocessing/        # Image/audio loaders
â”‚   â”œâ”€â”€ video/                # Frame extraction
â”‚   â””â”€â”€ audio/                # Audio inference
â”‚
â”œâ”€â”€ scripts/                   # Training & testing scripts
â”œâ”€â”€ models/                    # Trained model weights
â”œâ”€â”€ uploads/                   # Runtime uploads
â”œâ”€â”€ temp_frames/               # Video frames
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runtime.txt
â””â”€â”€ README.md
ðŸ› ï¸ Running Locally
1ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
3ï¸âƒ£ Start backend
uvicorn backend.app:app --reload
API available at:
http://127.0.0.1:8000/docs
ðŸ”Œ API Usage
POST /predict
Supports:
.jpg .png
.mp4 .avi
.wav
Example response
{
  "type": "image",
  "fake_probability": 78.32,
  "real_probability": 21.68,
  "verdict": "FAKE",
  "confidence": 56.64
}
ðŸ§ª Model Training
Image Dataset Structure
datasets/images/
â”œâ”€â”€ real/
â””â”€â”€ fake/
Train:
python -m scripts.train_image_model
Audio Dataset Structure
datasets/audio/
â”œâ”€â”€ real/
â””â”€â”€ fake/
Train:
python -m scripts.train_audio_model
ðŸš€ Deployment (Render)
Service Type
Web Service
Build Command
pip install -r requirements.txt
Start Command
uvicorn backend.app:app --host 0.0.0.0 --port $PORT
runtime.txt
python-3.11.9
âš ï¸ Important Deployment Notes
Render has no GPU
CPU-only PyTorch must be used
GPU torch will crash builds
UNCERTAIN results are expected & healthy
ðŸ“Š Accuracy Expectations (Realistic)
Media	Good Accuracy
Images	85â€“92%
Video	80â€“90%
Audio	90%+
âš ï¸ 99% accuracy usually means overfitting
ðŸ§  Key Design Principles
Never blindly accuse
Prefer uncertainty over false positives
Combine multiple signals
Calibrate confidence
Be explainable
Be responsible
ðŸ”® Future Enhancements
Temporal CNNs (I3D / X3D)
Frequency-domain fusion
Grad-CAM heatmaps in UI
Ensemble image models
Cryptographic media fingerprinting
Blockchain authenticity proofs